{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting Faker\n",
      "  Downloading faker-37.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\wasadmin\\appdata\\roaming\\python\\python312\\site-packages (from Faker) (2024.1)\n",
      "Downloading faker-37.4.0-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.9 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.9 MB 330.3 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.9 MB 409.6 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/1.9 MB 393.8 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.9 MB 602.4 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 7.3 MB/s eta 0:00:00\n",
      "Installing collected packages: Faker\n",
      "Successfully installed Faker-37.4.0\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "Gender\n",
      "Education Level\n",
      "Job Title\n",
      "Years of Experience\n",
      "Salary\n",
      "Country\n",
      "Race\n",
      "Senior\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def load_kaggle_data():\n",
    "    file_path = Path(\"./datasets/archive.zip\")\n",
    "    if not file_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://www.kaggle.com/api/v1/datasets/download/amirmahdiabbootalebi/salary-by-job-title-and-country\"\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "    zf = zipfile.ZipFile(\"./datasets/archive.zip\")\n",
    "\n",
    "    return pd.read_csv(zf.open('Salary.csv'))\n",
    "\n",
    "kaggle_data = load_kaggle_data ()\n",
    "print (*kaggle_data.columns, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Copy dataset and only take the columns we need\n",
    "dataset_clean = kaggle_data[[\"Salary\", \"Country\", \"Job Title\"]]\n",
    "\n",
    "# Rename the columns that were copied\n",
    "dataset_clean = dataset_clean.rename (columns={\"Salary\": \"salary\", \"Country\": \"work_location\", \"Job Title\": \"job_role\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male images: (2515,)\n",
      "Female images: (2485,)\n"
     ]
    }
   ],
   "source": [
    "def getFromUrl (url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Read the response data\n",
    "        data = response.read().decode('utf-8')\n",
    "        \n",
    "        # Parse the JSON data\n",
    "        json_data = json.loads(data)\n",
    "        \n",
    "        return json_data\n",
    "\n",
    "user_images = np.array (getFromUrl (f\"https://randomuser.me/api/?inc=picture&results=5000&seed={SEED}\")[\"results\"])\n",
    "\n",
    "male_urls = []\n",
    "female_urls = []\n",
    "\n",
    "# Extract and categorize the URLs\n",
    "for user in user_images:\n",
    "    thumbnail_url = user[\"picture\"][\"thumbnail\"]\n",
    "    if \"women\" in thumbnail_url or \"female\" in thumbnail_url:\n",
    "        female_urls.append(thumbnail_url)\n",
    "    elif \"men\" in thumbnail_url or \"male\" in thumbnail_url:\n",
    "        male_urls.append(thumbnail_url)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "user_images_male = np.array(male_urls)\n",
    "user_images_female = np.array(female_urls)\n",
    "\n",
    "print(f\"Male images: {user_images_male.shape}\")\n",
    "print(f\"Female images: {user_images_female.shape}\")\n",
    "\n",
    "np.save (\"./datasets/user_images_male.npy\", user_images_male)\n",
    "np.save (\"./datasets/user_images_female.npy\", user_images_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock data for the remaininig columns\n",
    "Faker.seed(SEED)\n",
    "faker = Faker()\n",
    "random.seed (SEED)\n",
    "\n",
    "def generateGender ():\n",
    "    rng = random.random()\n",
    "\n",
    "    if rng < 0.50:\n",
    "        return \"m\"\n",
    "    else:\n",
    "        return \"f\"\n",
    "    \n",
    "def generateNameForGender (gender):\n",
    "    if gender == \"m\":\n",
    "        return faker.name_male ()\n",
    "    elif gender == \"f\":\n",
    "        return faker.name_female ()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gender provided: \" + str(gender))\n",
    "    \n",
    "def generatePicForGender (gender):\n",
    "    if gender == \"m\":\n",
    "        return np.random.choice (user_images_male)\n",
    "    elif gender == \"f\":\n",
    "        return np.random.choice (user_images_female)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gender provided: \" + str(gender))\n",
    "    \n",
    "def generateReportsTo ():\n",
    "    return random.randint (1, len (dataset_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary\n",
      "work_location\n",
      "job_role\n",
      "id\n",
      "gender\n",
      "name\n",
      "pfp\n",
      "reports_to\n",
      "phone_number\n",
      "     salary work_location           job_role  id gender               name  \\\n",
      "0   90000.0            UK  Software Engineer   0      f       Allison Hill   \n",
      "1   65000.0           USA       Data Analyst   1      m        Noah Rhodes   \n",
      "2  150000.0        Canada            Manager   2      m  Brandon Henderson   \n",
      "3   60000.0           USA    Sales Associate   3      m      Daniel Wagner   \n",
      "4  200000.0           USA           Director   4      f   Christina Santos   \n",
      "\n",
      "                                                 pfp  reports_to phone_number  \n",
      "0  https://randomuser.me/api/portraits/thumb/wome...        3798   6344180831  \n",
      "1  https://randomuser.me/api/portraits/thumb/men/...        5542   7733950591  \n",
      "2  https://randomuser.me/api/portraits/thumb/men/...        1837   5833830965  \n",
      "3  https://randomuser.me/api/portraits/thumb/men/...        5306   2104000652  \n",
      "4  https://randomuser.me/api/portraits/thumb/wome...        5622   5697380399  \n"
     ]
    }
   ],
   "source": [
    "dataset_clean[\"id\"] = [i for i in range (len (dataset_clean))]\n",
    "dataset_clean[\"gender\"] = [generateGender () for i in range (len (dataset_clean))]\n",
    "dataset_clean[\"name\"] = dataset_clean[\"gender\"].apply(generateNameForGender)\n",
    "dataset_clean[\"pfp\"] = dataset_clean[\"gender\"].apply(generatePicForGender)\n",
    "dataset_clean[\"reports_to\"] = [generateReportsTo () for i in range (len (dataset_clean))]\n",
    "dataset_clean[\"phone_number\"] = [f\"{random.randint(200, 999):03d}{random.randint(200, 999):03d}{random.randint(200, 999):04d}\" for i in range (len (dataset_clean))]\n",
    "\n",
    "print (*dataset_clean.columns, sep=\"\\n\")\n",
    "print (dataset_clean.head ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Save the data to the disk\n",
    "FILENAME = \"./datasets/dataset_clean\"\n",
    "dataset_clean.to_parquet (FILENAME + \".parquet\")\n",
    "dataset_clean.to_json (FILENAME + \".json\", orient='records', indent=4)\n",
    "\n",
    "# Save the data to the database\n",
    "# try:\n",
    "#     MONGO_URI = \"mongodb://localhost:27017/employeeDB\"\n",
    "#     MONGO_COLLECTION = \"employees\"\n",
    "#     result = subprocess.run([\"mongoimport\", \"--uri\", MONGO_URI, \"--collection\", MONGO_COLLECTION, \"--drop\", \"--file\", FILENAME + \".json\", \"--jsonArray\"], capture_output=True, text=True, check=True)\n",
    "\n",
    "#     print(\"Standard Output:\")\n",
    "#     print(result.stdout)\n",
    "#     print(\"Standard Error:\")\n",
    "#     print(result.stderr)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(f\"Error executing command: {e}\")\n",
    "#     print(f\"Return Code: {e.returncode}\")\n",
    "#     print(f\"Output: {e.output}\")\n",
    "#     print(f\"Error Output: {e.stderr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
